{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#[Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one\n",
        "import numpy as np\n",
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        F = len(self.w)\n",
        "        N_in = len(x)\n",
        "        N_out = N_in - F + 1\n",
        "        a = np.zeros(N_out)\n",
        "\n",
        "        for i in range(N_out):\n",
        "            a[i] = np.dot(x[i:i+F], self.w) + self.b\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        F = len(self.w)\n",
        "        N_in = len(self.x)\n",
        "        N_out = len(da)\n",
        "\n",
        "        db = np.sum(da)\n",
        "\n",
        "        dw = np.zeros(F)\n",
        "        for s in range(F):\n",
        "            dw[s] = np.sum(da * self.x[s:s+N_out])\n",
        "\n",
        "        dx = np.zeros(N_in)\n",
        "        for j in range(N_in):\n",
        "            for s in range(F):\n",
        "                i = j - s\n",
        "                if 0 <= i < N_out:\n",
        "                    dx[j] += da[i] * self.w[s]\n",
        "\n",
        "        return db, dw, dx\n"
      ],
      "metadata": {
        "id": "daD3n_3KSExo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 2] Output size calculation after one-dimensional convolution\n",
        "def output_size_calculation(n_in, F, P=0, S=1):\n",
        "    return int((n_in + 2 * P - F) / S + 1)\n"
      ],
      "metadata": {
        "id": "E3Okyq57SEuQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 3] Experiment of one-dimensional convolutional layer with small array\n",
        "x = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = 1\n",
        "\n",
        "simple_conv_1d = SimpleConv1d(w, b)\n",
        "\n",
        "a = simple_conv_1d.forward(x)\n",
        "print(\"Forward output:\", a)\n",
        "\n",
        "da = np.array([10, 20])\n",
        "db, dw, dx = simple_conv_1d.backward(da)\n",
        "print(\"db:\", db)\n",
        "print(\"dw:\", dw)\n",
        "print(\"dx:\", dx)\n",
        "\n",
        "n_out = output_size_calculation(len(x), len(w))\n",
        "print(\"Output size:\", n_out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQiqOvWuSX6_",
        "outputId": "515e714b-f498-4e3a-90ee-1278d1f142b9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output: [35. 50.]\n",
            "db: 30\n",
            "dw: [ 50.  80. 110.]\n",
            "dx: [ 30. 110. 170. 140.]\n",
            "Output size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels\n",
        "import numpy as np\n",
        "\n",
        "class Conv1d:\n",
        "    def __init__(self, w, b):\n",
        "\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        self.x = x\n",
        "        batch_size, in_channels, N_in = x.shape\n",
        "        out_channels, _, F = self.w.shape\n",
        "\n",
        "        N_out = N_in - F + 1\n",
        "        a = np.zeros((batch_size, out_channels, N_out))\n",
        "\n",
        "        for n in range(batch_size):\n",
        "            for oc in range(out_channels):\n",
        "                for i in range(N_out):\n",
        "                    a[n, oc, i] = np.sum(\n",
        "                        x[n, :, i:i+F] * self.w[oc, :, :]\n",
        "                    ) + self.b[oc]\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "\n",
        "        batch_size, out_channels, N_out = da.shape\n",
        "        _, in_channels, N_in = self.x.shape\n",
        "        _, _, F = self.w.shape\n",
        "\n",
        "        db = np.zeros(out_channels)\n",
        "        dw = np.zeros_like(self.w)\n",
        "        dx = np.zeros_like(self.x)\n",
        "\n",
        "        for n in range(batch_size):\n",
        "            for oc in range(out_channels):\n",
        "                db[oc] += np.sum(da[n, oc, :])\n",
        "                for ic in range(in_channels):\n",
        "                    for i in range(N_out):\n",
        "                        dw[oc, ic, :] += da[n, oc, i] * self.x[n, ic, i:i+F]\n",
        "                        for s in range(F):\n",
        "                            dx[n, ic, i+s] += da[n, oc, i] * self.w[oc, ic, s]\n",
        "        return db, dw, dx\n"
      ],
      "metadata": {
        "id": "gBVs5yU2S-ih"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5]\n",
        "])\n",
        "x = x[np.newaxis, :, :]\n",
        "\n",
        "w = np.ones((3, 2, 3))\n",
        "b = np.array([1, 2, 3])\n",
        "\n",
        "conv = Conv1d(w, b)\n",
        "a = conv.forward(x)\n",
        "print(a[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IigQgKoNTlrE",
        "outputId": "98cc9ae1-46ca-4aa2-a344-107bbecddfbe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 5] (Advanced task) Implementing padding\n",
        "def pad_input(x, P):\n",
        "\n",
        "    if P == 0:\n",
        "        return x\n",
        "    return np.pad(x, ((0,0),(0,0),(P,P)), mode=\"constant\", constant_values=0)\n",
        "def forward(self, x, padding=0):\n",
        "    self.x = pad_input(x, padding)\n",
        "    self.padding = padding\n",
        "    batch_size, in_channels, N_in = self.x.shape\n",
        "    out_channels, _, F = self.w.shape\n",
        "\n",
        "    N_out = N_in - F + 1\n",
        "    a = np.zeros((batch_size, out_channels, N_out))\n",
        "\n",
        "    for n in range(batch_size):\n",
        "        for oc in range(out_channels):\n",
        "            for i in range(N_out):\n",
        "                a[n, oc, i] = np.sum(\n",
        "                    self.x[n, :, i:i+F] * self.w[oc, :, :]\n",
        "                ) + self.b[oc]\n",
        "    return a\n",
        "\n"
      ],
      "metadata": {
        "id": "6NSs8S3UTqsL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 6] (Advanced task) Response to mini batch\n",
        "x_batch = np.array([\n",
        "    [[1, 2, 3, 4], [2, 3, 4, 5]],  # sample 1\n",
        "    [[5, 6, 7, 8], [1, 0, 1, 0]]   # sample 2\n",
        "])  # shape (2, 2, 4)\n",
        "\n",
        "w = np.ones((3, 2, 3))\n",
        "b = np.array([1, 2, 3])\n",
        "\n",
        "conv = Conv1d(w, b)\n",
        "\n",
        "# Forward\n",
        "a_batch = conv.forward(x_batch)\n",
        "print(\"Forward output shape:\", a_batch.shape)\n",
        "\n",
        "da_batch = np.ones_like(a_batch)\n",
        "\n",
        "db, dw, dx_batch = conv.backward(da_batch)\n",
        "\n",
        "print(\"db:\", db.shape)\n",
        "print(\"dw:\", dw.shape)\n",
        "print(\"dx shape:\", dx_batch.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X5CaGR_Txoa",
        "outputId": "ced1594f-7228-4c84-d9d0-29dccbca295b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output shape: (2, 3, 2)\n",
            "db: (3,)\n",
            "dw: (3, 2, 3)\n",
            "dx shape: (2, 2, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 7] (Advance assignment) Arbitrary number of strides\n",
        "\n",
        "def forward(self, x, padding=0, stride=1):\n",
        "    self.x = pad_input(x, padding)\n",
        "    self.padding = padding\n",
        "    self.stride = stride\n",
        "    batch_size, in_channels, N_in = self.x.shape\n",
        "    out_channels, _, F = self.w.shape\n",
        "\n",
        "    N_out = int((N_in - F) / stride) + 1\n",
        "    a = np.zeros((batch_size, out_channels, N_out))\n",
        "\n",
        "    for n in range(batch_size):\n",
        "        for oc in range(out_channels):\n",
        "            for i in range(N_out):\n",
        "                start = i * stride\n",
        "                a[n, oc, i] = np.sum(\n",
        "                    self.x[n, :, start:start+F] * self.w[oc, :, :]\n",
        "                ) + self.b[oc]\n",
        "    return a\n"
      ],
      "metadata": {
        "id": "221vojqMT-n4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "#[Problem 8] Learning and estimation\n",
        "class SimpleFC:\n",
        "    def __init__(self, in_features, out_features, lr=0.01):\n",
        "        self.W = np.random.randn(in_features, out_features) * np.sqrt(1. / in_features)\n",
        "        self.b = np.zeros(out_features)\n",
        "        self.lr = lr\n",
        "\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x, self.W) + self.b\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        batch_size = self.x.shape[0]\n",
        "\n",
        "        dW = np.dot(self.x.T, grad_output) / batch_size\n",
        "        db = np.sum(grad_output, axis=0) / batch_size\n",
        "        dx = np.dot(grad_output, self.W.T)\n",
        "\n",
        "        self.W -= self.lr * dW\n",
        "        self.b -= self.lr * db\n",
        "\n",
        "        return dx\n",
        "\n",
        "class Conv1dNet:\n",
        "    def __init__(self, in_features, conv_out_channels, conv_filter_size, num_classes, lr=0.01):\n",
        "        in_channels = 1\n",
        "        w = np.random.randn(conv_out_channels, in_channels, conv_filter_size) * np.sqrt(1/(in_channels*conv_filter_size))\n",
        "        b = np.zeros(conv_out_channels)\n",
        "        self.conv = Conv1d(w, b)\n",
        "\n",
        "        self.conv_out_size = output_size_calculation(in_features, conv_filter_size)\n",
        "\n",
        "        self.fc = SimpleFC(conv_out_channels * self.conv_out_size, num_classes, lr)\n",
        "        self.lr = lr\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs=3, batch_size=64):\n",
        "        in_channels = 1\n",
        "        N = len(X_train)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            perm = np.random.permutation(N)\n",
        "            X_train = X_train[perm]\n",
        "            y_train = y_train[perm]\n",
        "\n",
        "            epoch_loss = 0\n",
        "            for i in range(0, N, batch_size):\n",
        "                x_batch = X_train[i:i+batch_size]\n",
        "                y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "                bs = len(x_batch)\n",
        "                x_batch_conv = x_batch.reshape(bs, in_channels, -1)\n",
        "\n",
        "                conv_out = self.conv.forward(x_batch_conv)\n",
        "                relu_out = np.maximum(conv_out, 0)\n",
        "\n",
        "                fc_in = relu_out.reshape(bs, -1)\n",
        "\n",
        "                logits = self.fc.forward(fc_in)\n",
        "\n",
        "                exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
        "                probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "                loss = -np.log(probs[np.arange(bs), y_batch] + 1e-9).mean()\n",
        "                epoch_loss += loss * bs\n",
        "\n",
        "                grad_logits = probs\n",
        "                grad_logits[np.arange(bs), y_batch] -= 1\n",
        "                grad_logits /= bs\n",
        "\n",
        "                grad_fc_in = self.fc.backward(grad_logits)\n",
        "                grad_relu = grad_fc_in.reshape(relu_out.shape)\n",
        "                grad_conv = grad_relu * (conv_out > 0)\n",
        "\n",
        "                self.conv.backward(grad_conv)\n",
        "\n",
        "            epoch_loss /= N\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    def predict(self, X_test, y_test=None):\n",
        "        in_channels = 1\n",
        "        N = len(X_test)\n",
        "        batch_size = 64\n",
        "        correct = 0\n",
        "\n",
        "        for i in range(0, N, batch_size):\n",
        "            x_batch = X_test[i:i+batch_size]\n",
        "            bs = len(x_batch)\n",
        "            x_batch_conv = x_batch.reshape(bs, in_channels, -1)\n",
        "\n",
        "            conv_out = self.conv.forward(x_batch_conv)\n",
        "            relu_out = np.maximum(conv_out, 0)\n",
        "            fc_in = relu_out.reshape(bs, -1)\n",
        "            logits = self.fc.forward(fc_in)\n",
        "\n",
        "            preds = np.argmax(logits, axis=1)\n",
        "            if y_test is not None:\n",
        "                correct += np.sum(preds == y_test[i:i+bs])\n",
        "\n",
        "        if y_test is not None:\n",
        "            return correct / N\n",
        "        else:\n",
        "            return preds\n"
      ],
      "metadata": {
        "id": "ikv08eOTaJDB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
        "\n",
        "model = Conv1dNet(in_features=784, conv_out_channels=4, conv_filter_size=5, num_classes=10, lr=0.01)\n",
        "model.fit(X_train[:1000], y_train[:1000], epochs=3, batch_size=64)\n",
        "acc = model.predict(X_test[:500], y_test[:500])\n",
        "print(f\"Test accuracy ): {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqq4qjmRaSbX",
        "outputId": "a5231049-b3c4-44b3-9b38-a369c13c27e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 2.3087\n",
            "Epoch 2/3 - Loss: 2.3068\n",
            "Epoch 3/3 - Loss: 2.3049\n",
            "Test accuracy (small subset): 0.1280\n"
          ]
        }
      ]
    }
  ]
}