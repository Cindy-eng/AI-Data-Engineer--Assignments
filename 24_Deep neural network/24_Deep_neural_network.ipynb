{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zRJUvjIr62Ra"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#[Problem 1] Classifying fully connected layers\n",
        "\n",
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = self.initializer.B(n_nodes2)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        A = np.dot(X, self.W) + self.B\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        batch_size = self.X.shape[0]\n",
        "        self.dW = np.dot(self.X.T, dA) / batch_size\n",
        "        self.dB = np.mean(dA, axis=0)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "        self.optimizer.update(self)\n",
        "        return dZ\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 2] Classifying the initialization method\n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2)\n",
        "        return B\n"
      ],
      "metadata": {
        "id": "BNxYuPgA6_06"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 3] Classifying optimization methods\n",
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return layer\n"
      ],
      "metadata": {
        "id": "ltlB-urI7Ppl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 4] Classifying activation functions\n",
        "\n",
        "class SoftmaxCrossEntropy:\n",
        "    def forward(self, Z):\n",
        "        exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "        self.A = exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, Z, Y):\n",
        "        batch_size = Y.shape[0]\n",
        "        dZ = (self.A - Y) / batch_size\n",
        "        return dZ\n"
      ],
      "metadata": {
        "id": "HuqUY9lN7YQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 5] ReLU class creation\n",
        "class ReLU:\n",
        "    def forward(self, X):\n",
        "        self.mask = (X > 0)\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        return dZ * self.mask\n",
        "\n"
      ],
      "metadata": {
        "id": "4IUCLEHv7iwt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 6] Initial value of weight\n",
        "class XavierInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        sigma = 1.0 / np.sqrt(n_nodes1)\n",
        "        return sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return np.zeros(n_nodes2)\n",
        "\n",
        "class HeInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        sigma = np.sqrt(2.0 / n_nodes1)\n",
        "        return sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return np.zeros(n_nodes2)\n",
        "\n"
      ],
      "metadata": {
        "id": "NHBv9dg_7mHV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 7] Optimization method\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr=0.01, epsilon=1e-8):\n",
        "        self.lr = lr\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def update(self, layer):\n",
        "        if not hasattr(layer, \"h_W\"):\n",
        "            layer.h_W = np.zeros_like(layer.W)\n",
        "            layer.h_B = np.zeros_like(layer.B)\n",
        "\n",
        "        layer.h_W += layer.dW ** 2\n",
        "        layer.h_B += layer.dB ** 2\n",
        "\n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.h_W) + self.epsilon)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.h_B) + self.epsilon)\n",
        "\n",
        "        return layer"
      ],
      "metadata": {
        "id": "NFi4eYHQ7z1U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 8] Class completion\n",
        "class ScratchDeepNeuralNetworkClassifier:\n",
        "    def __init__(self, n_features, n_hidden_nodes_list, n_output,\n",
        "                 initializer, optimizer, activations):\n",
        "        self.layers = []\n",
        "        self.activations = activations\n",
        "\n",
        "        layer_sizes = [n_features] + n_hidden_nodes_list + [n_output]\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            fc = FC(layer_sizes[i], layer_sizes[i+1], initializer, optimizer)\n",
        "            self.layers.append(fc)\n",
        "\n",
        "    def forward(self, X):\n",
        "        A = X\n",
        "        for layer, activation in zip(self.layers, self.activations):\n",
        "            Z = layer.forward(A)\n",
        "            A = activation.forward(Z)\n",
        "        return A\n",
        "\n",
        "    def backward(self, Z_last, Y):\n",
        "        dA = self.activations[-1].backward(Z_last, Y)\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            dZ = self.layers[i].backward(dA)\n",
        "            if i != 0:\n",
        "                dA = self.activations[i-1].backward(dZ)\n",
        "\n",
        "    def fit(self, X, Y, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            Z_last = self.forward(X)\n",
        "            self.backward(Z_last, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        Z_last = self.forward(X)\n",
        "        return np.argmax(Z_last, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "lXTjeXQN75xR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "mnist = fetch_openml(\"mnist_784\", version=1)\n",
        "X = mnist.data.astype(np.float32) / 255.0\n",
        "y = mnist.target.astype(np.int64)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_onehot = one_hot_encode(y_train, 10)\n",
        "optimizer = AdaGrad(lr=0.01)\n",
        "initializer = XavierInitializer()\n",
        "activations = [ReLU(), ReLU(), SoftmaxCrossEntropy()]\n",
        "\n",
        "model = ScratchDeepNeuralNetworkClassifier(\n",
        "    n_features=784,\n",
        "    n_hidden_nodes_list=[128, 64],\n",
        "    n_output=10,\n",
        "    initializer=initializer,\n",
        "    optimizer=optimizer,\n",
        "    activations=activations\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train_onehot, epochs=10)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v92VA7Eo8j5a",
        "outputId": "f1a01bf2-f9ca-4e5f-b3e7-7fd8dd78819a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 9] Learning and estimation\n",
        "def one_hot_encode(Y, n_classes):\n",
        "    return np.eye(n_classes)[Y]\n",
        "\n",
        "\n",
        "n_features = 784\n",
        "n_hidden = [128, 64]\n",
        "n_output = 10\n",
        "initializer = XavierInitializer()\n",
        "optimizer = AdaGrad(lr=0.01)\n",
        "activations = [ReLU(), ReLU(), SoftmaxCrossEntropy()]\n",
        "\n",
        "model = ScratchDeepNeuralNetworkClassifier(n_features, n_hidden, n_output,\n",
        "                                           initializer, optimizer, activations)\n",
        "\n",
        "Y_train_onehot = one_hot_encode(y_train, n_output)\n",
        "model.fit(X_train, Y_train_onehot, epochs=20)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "accuracy = np.mean(Y_pred == y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL6gQvKX7_ih",
        "outputId": "ade01468-b554-49ac-eb48-eef4de9d2f5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8499\n"
          ]
        }
      ]
    }
  ]
}