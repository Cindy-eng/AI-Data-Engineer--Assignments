{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJvYUKNLp3Oh",
        "outputId": "888c08be-edca-4b60-b3ad-f91fdfe3bf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.4559 - val_accuracy: 0.9632 - val_loss: 0.1288\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1272 - val_accuracy: 0.9727 - val_loss: 0.0931\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0848 - val_accuracy: 0.9722 - val_loss: 0.0890\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0603 - val_accuracy: 0.9767 - val_loss: 0.0769\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0473 - val_accuracy: 0.9777 - val_loss: 0.0768\n"
          ]
        }
      ],
      "source": [
        "#[Problem 1] Sharing and executing the official tutorial mode\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 2] (Advance assignment) Execute various methods\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "detect_fn = tf.saved_model.load(\"path/to/saved_model\")\n",
        "\n",
        "img = Image.open(\"image.jpg\").convert(\"RGB\")\n",
        "img_np = np.array(img)\n",
        "input_tensor = tf.convert_to_tensor(img_np)[tf.newaxis, ...]\n",
        "\n",
        "outputs = detect_fn(input_tensor)\n",
        "\n",
        "boxes = outputs[\"detection_boxes\"][0].numpy()\n",
        "classes = outputs[\"detection_classes\"][0].numpy().astype(np.int32)\n",
        "scores = outputs[\"detection_scores\"][0].numpy()\n",
        "\n",
        "keep = scores > 0.5\n",
        "boxes, classes, scores = boxes[keep], classes[keep], scores[keep]\n",
        "print(\"Detections:\", list(zip(classes.tolist(), scores.tolist())))\n",
        "\n",
        "def draw_box(ax, box):\n",
        "    h, w = img_np.shape[:2]\n",
        "    y1, x1, y2, x2 = box\n",
        "    ax.add_patch(plt.Rectangle((x1*w, y1*h), (x2-x1)*w, (y2-y1)*h,\n",
        "                               fill=False, linewidth=2))\n",
        "\n",
        "fig = plt.figure(figsize=(8,6)); ax = plt.gca(); ax.imshow(img_np); ax.axis('off')\n",
        "for b in boxes: draw_box(ax, b)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "aIPdLJvnuf6M",
        "outputId": "6a6f97f7-34c4-4685-ec1c-ebe7f82b1c7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "SavedModel file does not exist at: path/to/saved_model/{saved_model.pbtxt|saved_model.pb}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3325923563.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdetect_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/saved_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m-> 1016\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   debug_info_path = file_io.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: path/to/saved_model/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 3] Learning Iris (binary classification) with Keras\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "mask = y != 0\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "y = LabelEncoder().fit_transform(y)  # 0 or 1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(8, activation=\"relu\", input_shape=(4,)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Binary Iris accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qg3E3bZq22b",
        "outputId": "6b37d3be-fb15-47b6-a54c-474f8eae85ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Iris accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 4] Learn Iris (multi-level classification) with Keras\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = to_categorical(iris.target, 3)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(10, activation=\"relu\", input_shape=(4,)),\n",
        "    Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Multi-class Iris accuracy: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsRlrmZKrupc",
        "outputId": "0ea54da8-ecdd-480c-b883-dacf94ad15b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-class Iris accuracy: 0.6333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 5] Learning House Prices with Keras\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "X = data.drop(\"SalePrice\", axis=1).select_dtypes(include=[np.number]).fillna(0)\n",
        "y = data[\"SalePrice\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "model.fit(X_train, y_train, epochs=50, verbose=0, validation_split=0.1)\n",
        "\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"House Prices MAE: {mae:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnDrDNA6sbNP",
        "outputId": "d20793f2-c72c-43e1-d035-12d016d6b691"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "House Prices MAE: 96442.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 6] Learning MNIST with Keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"MNIST accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjQt4NqBtGFm",
        "outputId": "022c6ad2-9fa6-4a35-9c6a-39eaa0254b7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.8973 - loss: 0.3577 - val_accuracy: 0.9798 - val_loss: 0.0724\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step - accuracy: 0.9806 - loss: 0.0644 - val_accuracy: 0.9845 - val_loss: 0.0548\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 34ms/step - accuracy: 0.9884 - loss: 0.0386 - val_accuracy: 0.9865 - val_loss: 0.0535\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.9918 - loss: 0.0262 - val_accuracy: 0.9877 - val_loss: 0.0468\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - accuracy: 0.9953 - loss: 0.0167 - val_accuracy: 0.9863 - val_loss: 0.0548\n",
            "MNIST accuracy: 0.9818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Problem 7] (Advance assignment) Rewriting to PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "mask = y != 0\n",
        "X, y = X[mask], y[mask]\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "class IrisBinaryNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(4, 8)\n",
        "        self.fc2 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return torch.sigmoid(self.fc2(x))\n",
        "\n",
        "model = IrisBinaryNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred_test = model(X_test).round()\n",
        "    acc = (y_pred_test.eq(y_test).sum().item()) / len(y_test)\n",
        "print(f\"PyTorch Binary Iris accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbn9Vm5ftOlZ",
        "outputId": "adb335bc-b26d-41df-93e6-9f0c9f11f8ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Binary Iris accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#[Problem 8] (Advance assignment) Comparison of frameworks\n",
        "\n",
        "TensorFlow is a very powerful and mature deep learning library that offers strong visualization capabilities and multiple options for high-level model development. It provides production-ready deployment solutions and supports mobile platforms, making it an excellent choice for developers who want to build models for real-world applications. TensorFlow is particularly useful when models need to be deployed on mobile devices, when robust community support and comprehensive documentation are desired, when rich learning resources such as MOOCs are needed, when TensorBoard visualization is important, or when large-scale distributed model building is required.\n",
        "\n",
        "PyTorch, on the other hand, is a fully featured framework for building deep learning models and is commonly used in applications such as image recognition and natural language processing. Written in Python, PyTorch is relatively easy for most machine learning developers to learn and use. It is distinctive for its excellent GPU support and its use of reverse-mode automatic differentiation, which allows computation graphs to be modified dynamically during runtime. This flexibility makes PyTorch particularly popular for fast experimentation and rapid prototyping.\n",
        "\n",
        "PyTorch was developed by Facebook AI Research along with several other labs. The framework combines efficient GPU-accelerated backend libraries from Torch with an intuitive Python frontend that emphasizes rapid prototyping, readable code, and support for a wide variety of deep learning models. Developers can use familiar imperative programming while still taking advantage of computation graphs. Since its open-source release in 2017, PyTorch’s Pythonic approach has made it a favorite among machine learning researchers and developers alike.\n",
        "\n",
        "Although still relatively young compared to TensorFlow, PyTorch has grown rapidly and is especially suitable for research or projects where strict production requirements are not critical. It provides an excellent development and debugging experience and appeals to developers who prefer the flexibility and expressiveness of Python."
      ],
      "metadata": {
        "id": "RHb4_OXizmyS"
      }
    }
  ]
}